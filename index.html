<!DOCTYPE html>
<html>
  <head>
    <title>Building for automation</title>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"
    />
    <link rel="stylesheet" type="text/css" href="./css/typo.css" />
    <link rel="stylesheet" type="text/css" href="./css/nord-dark.css" />
    <link rel="stylesheet" type="text/css" href="./css/font-nord.css" />
    <link rel="stylesheet" type="text/css" href="./css/bg-nord.css" />
    <link rel="stylesheet" type="text/css" href="./css/style.css" />
  </head>
  <body>
    <textarea id="source">
class: nord-dark, center, middle

## Building For automation
### Leveraging Data At Every Step Of The Process

???
Hey Guys -- For those of you who don't know me, my name is Tyler Parrott and I'm the product manager for a new application being developed in 
INO called Tracker.  I'll be giving you a quick intro to the tool itself, but this talk is more about how we're deploying this tool.

---

class: nord-dark, left, middle

### Background: Tracker 2.0

.fiftyfive[![tracker](images/landing_page.png)]

???
Just for a bit of background -- Tracker is a tool being developed in collaboration with TBS.  It's a tool used to scan the web/email configurations 
of GC domains and provide tailored security guidance based on the results.  At the moment, we're checking things like HTTPS/SSL/DMARC/SPF/DKIM.  
You'll notice it says 2.0 there -- that's because their is currently a tool in use at TBS that measures just HTTPS/SSL configs, but this is a complete rewrite.

We decided to follow TBS' Policy on service and digital as closely as possible for our development.  This policy covers concepts such as using cloud first,
supporting zero-downtime deployments, using distributed architectures, and adopting test driven development

---

class: nord-dark, center, middle

.logo[![tracker logo](images/tracker.png)]

## Tracker is Boring
### In many ways, Tracker is the least interesting thing about Tracker

???
But really, it's just a website that displays scan results, we've seen a millions of those, right?  I've found myself saying that Tracker itself is the least 
interesting part about the Tracker project numerous times throughout development, so I wanted to touch on some of those more interesting bits instead.

---

class: nord-dark, middle, left

### The goal: Make security visible

???
When we started development on this tool, one of our goals was to make security as transparent and accessible as possible.  And by security, I mean the controls 
themselves.  In general we do a pretty good job of seeding our environments with GC Guardrails and  monitoring with things like CBS, but how many GC deployments 
are able to tell you exactly what controls they have covered at any given time?  How many are able to tell you whether they've drifted from their approved configurations?

---

class: nord-dark, left, middle

### Can we build Tracker to support analysis?

* Design to answer the kind of questions security asks
  * "Is that encrypted?"
  * "Can those talk?"
  * "What ports are open?"
  * "What version are you running?"
  * "Are you vulnerable?"
  * "Is it exploitable?"

???
To that end, we wanted a design that could easily answer questions like these.

---

class: nord-dark, left, middle

### Analyzing any of this requires data

* Platform: *data*  (Kubernetes)
* Infrastructure: *data*  (Config Connector)
* Languages: *data*  (GitHub API)
* Dependencies: *data*  (GitHub API)
* Workflow (who, and how): *data*  (GitHub API)
* Application code: *data*  (GraphQL)
* Inputs & validation: *data*  (GraphQL)

???
In order to achieve this, we need data at every level.  Fortunately for us, we have it available at every layer of our deployment.  For our platform and infrastructure, 
we have our Kubernetes overlays.  For Languages/Dependencies/Workflow, we have the GitHub API, and for our Application level controls, we have GraphQL.

---

class: nord-dark, center, middle

## Platform as data: Kubernetes

???
Let's start with the platform.  TBS' Directive on Service and Digital states that moving forward, GC departments should develop applications in a cloud native manner 
wherever possible.  And while we probably over engineered this project by using Kubernetes, it gave us a ton of room to experiment with some new concepts.

---

class: nord-dark, middle, left

### Kubernetes
* describe your system with data
* execute that description
* *ensure system never deviates from the description*

.sync.sixty[![](images/kubernetes-sync.svg)]

???
Our focus during development was to treat our GitHub repo as a single source of truth.  We describe our system as YAML, execute that description, and ensure that the system 
never deviates from the description.

---

class: nord-dark, left, middle

### When system descriptions are YAML
* Data for analysis
* Simplified operations

???
So, what does this give us?  Well, when our entire system is described as data, then we now have the ability to ingest that data elsewhere for things like validation.  
It also simplifies operations, giving us the ability to do things like zero downtime deployments.

---

class: nord-dark, left, middle

### Operations

#### Deployment

```yaml
  -     - image: gcr.io/track-compliance/frontend:master-320b5fd
* +     - image: gcr.io/track-compliance/frontend:master-d07b6e0
```

#### Rollback

```yaml
* +     - image: gcr.io/track-compliance/frontend:master-320b5fd
  -     - image: gcr.io/track-compliance/frontend:master-d07b6e0
```

???
On the Operations side, it is now super simple for us to deploy and revert different aspects of our application.  All of this results in zero downtime and is completely 
transparent to the user.  We generally have at least 2 pods running for each of our application components, so we do a rolling replacement of them when new images
become available.

---

class: nord-dark, left, middle

### Analysis: Config on GitHub says...

```bash
$ git clone --depth 1 git@github.com:canada-ca/tracker.git && cd tracker
$ kustomize build platform/overlays/gke | \
>   yq 'select(.kind == "Service" and .spec.type == "LoadBalancer").spec.ports[].port'
80
443
```

???
On the analysis side, we can now check things like what ports are open on our deployment by using a simple search of our infrastructure data.

---

class: nord-dark, left, middle

### Analysis: System on Google Cloud shows

```bash
tyler@ghost:~$ sudo nmap -p- --reason tracker.alpha.canada.ca
Starting Nmap 7.80 ( https://nmap.org ) at 2021-03-01 14:47 AST
Nmap scan report for tracker.alpha.canada.ca (34.95.5.243)
Host is up, received syn-ack ttl 56 (0.058s latency).
rDNS record for 34.95.5.243: 243.5.95.34.bc.googleusercontent.com
Not shown: 65533 filtered ports
Reason: 65533 no-responses
PORT      STATE  SERVICE REASON
80/tcp    open   http    syn-ack ttl 56
443/tcp   open   https   syn-ack ttl 56

Nmap done: 1 IP address (1 host up) scanned in 191.39 seconds
```

???
Of course, you can still verify the old fashioned way....

---

class: nord-dark, middle, left

### Why this works
* Data is on GitHub
* Changes flow through

.gitops.sixty[![gitops](images/gitops2.svg)]

???
So, how do we know that our data will always reflect what's deployed?  Well, Tracker is built using test driven development.  As it stands, 
we now have somewhere near 3000 automated tests for our API alone, with roughly 99.85% coverage.  When a feature is considered production ready, 
the code is committed and a PR is made.  New PR's trigger the automated testing of the entire project to ensure that no existing functionality is broken.  
When all tests pass, the code is peer reviewed and then merged to master where all of our tests are run again, this time to verify the combination of the 
new feature with the code in the main branch also passes.

If all tests and validations are successful, a new docker image will be created and stored in our private container registry where our entire catalog is 
continually scanned for vulnerabilities.  The arrival of a new image is noticed by a service we run called Flux, which adds a commit of its own to the 
repository, modifying the system description to specify the use of this new image.  From there Flux syncs the config from the repo into the cluster and K8s 
automatically performs a zero downtimes deployment of the new image.

By doing things this way, we have completely eliminated configuration drift.  Our deployment is always a reflection of our master repo.  Flux deletes 
anything it finds in the cluster that is not from the config and does not allow things like SSH/RDP since these mechanisms change the system in ways 
that aren't captured in version control.  Also, driving system state changes from version control provides us with an immutable audit trail.

---

class: nord-dark, middle, left

### Bringing these ideas to the infrastructure layer...

???
So that's pretty cool, right?  We're also able to automate all of our application deployment using service accounts, meaning no personal accounts need 
to touch deployments and even if they do, whatever they manage to change will be caught and reverted by Flux within minutes.  This adds another layer of
security since every system change requires a peer reviewed pull request that can be audited at any time. Can the same idea be 
applied to infrastructure provisioning?

---

class: nord-dark, middle, left

### Infrastructure as Data: Config Connector

* Describe GCP infra/services in Kubernetes data format
* Extends Kubernetes to act on these new types

.sync.sixty[![](images/config-connector-sync.svg)]

???
As it turns out, yes!  There are several tools out there that allow this, but we landed on Google's Config Connector.  Config Connector allows us to 
manage Google cloud resources from Kubernetes, which gives us the power to manage our infrastructure the same way as we're managing our application -- 
through peer reviewed, auditable pull requests that are automatically deployed once merged to master.  So if I want to scale my database, rather than
manipulating the cluster directly, I would edit the database YAML description, commit it, and merge it down once it passes peer review.  From there 
Config Connector would handle the provisining within the cluster.

---

class: nord-dark, middle, left

### Hosted SQL database "as data"

```yaml
apiVersion: sql.cnrm.cloud.google.com/v1beta1
* kind: SQLInstance
metadata:
  name: sqluser-dep
spec:
  region: northamerica-northeast1
  databaseVersion: MYSQL_5_7
  settings:
    backupConfiguration:
        enabled: true
        binaryLogEnabled: true
        startTime: "18:00"
    ipConfiguration:
      requireSsl: true
    tier: db-n1-standard-1
```

???
Here's an example of infrastructure as data -- it's a really simple YAML file that describes a MySQL instance.

---

class: nord-dark, middle, left


### When our description is YAML...

???
As I mentioned earlier, when you have your system described this way and your deployment always matches the description, it becomes multi-purpose.

---

class: nord-dark, middle, left

### Policy: Meets data residency requirements?

```yaml
apiVersion: sql.cnrm.cloud.google.com/v1beta1
kind: SQLInstance
metadata:
  name: sqluser-dep
spec:
*  region: northamerica-northeast1
  databaseVersion: MYSQL_5_7
  settings:
    backupConfiguration:
        enabled: true
        binaryLogEnabled: true
        startTime: "18:00"
    ipConfiguration:
      requireSsl: true
    tier: db-n1-standard-1
```

???
We can use this description to verify that it meets data residency requirements...

---

class: nord-dark, middle, left

### Operations: Are backups getting done?

```yaml
apiVersion: sql.cnrm.cloud.google.com/v1beta1
kind: SQLInstance
metadata:
  name: sqluser-dep
spec:
  region: northamerica-northeast1
  databaseVersion: MYSQL_5_7
  settings:
*    backupConfiguration:
*        enabled: true
        binaryLogEnabled: true
        startTime: "18:00"
    ipConfiguration:
      requireSsl: true
    tier: db-n1-standard-1
```

???
Or to ensure backups are being performed...

---

class: nord-dark, middle, left

### Security: Encryption in transit?

```yaml
apiVersion: sql.cnrm.cloud.google.com/v1beta1
kind: SQLInstance
metadata:
  name: sqluser-dep
spec:
  region: northamerica-northeast1
  databaseVersion: MYSQL_5_7
  settings:
    backupConfiguration:
        enabled: true
        binaryLogEnabled: true
        startTime: "18:00"
    ipConfiguration:
*      requireSsl: true
    tier: db-n1-standard-1
```

???
Or to ensure encryption in transit...

---

class: nord-dark, middle, left

### Unlike Word Docs, data is dual use
* Always up to date because it's needed for operations
* YAML is human readable, supporting manual analysis
* YAML is machine readable supporting automated analysis

???
A lot of our desire to leverage the data in our system came when we started to undergo the SA&A process -- which is a 
bunch of spreadsheets and screenshots that didn't seem all that useful to us as operators of the system.  What happens 
to that stuff once the SA&A is over?  Does anyone reference it?  Are deployments checked to see if they're still within 
their ATO parameters?  Leveraging our data for more than just deployment opens up a litany of new possibilities for security 
and audit.

---

class: nord-dark, middle, left

### Data as documentation
* We can ensure this documentation reflects reality

.configconnector.eighty[![gitops](images/gitops.svg)]

???
And again, when deployed in an automated fashion, our data always reflects reality

---

class: nord-dark, middle, left

### Can we build Tracker to support analysis?

* More than we thought!
* Everything from service accounts to input validation is visible from the outside
* Tracker is now data that can be input in to some other process

???
So can we build Tracker to support analysis?  As it turns out, for the most part, yes.  Every single aspect of our deployment process is described 
as data somewhere visible to the outside.

---

class: nord-dark, left, middle

### The concept: limit access to actual cluster resources by representing everything you can as data and validate that instead

???
Our end goal is this -- limit the need to provide access to the live cluster itself.  If our own developers don't even need access, 
why should anyone else?  Obviously there might be some limitations to this concept, but for the most part we want to keep the validation 
of security controls focused on our data

---

class: nord-dark, middle, left

### Proof of concept: Generating ITSG controls

```bash
$ cat sqlinstance.yaml
apiVersion: sql.cnrm.cloud.google.com/v1beta1
kind: SQLInstance
metadata:
  name: sqluser-dep
spec:
  region: northamerica-northeast1
  databaseVersion: MYSQL_5_7
  settings:
    backupConfiguration:
      enabled: true
      binaryLogEnabled: true
      startTime: "18:00"
    ipConfiguration:
      requireSsl: true
    tier: db-n1-standard-1

```

???
This goal lead us to a proof of concept.  Here on screen we have the same SQL Instance I alluded to earlier...

---

class: nord-dark, middle, left, smaller-text

### Proof of concept: Generating ITSG controls

```bash
$ cat sqlinstance.yaml | ./itsg
{
  "CP-9": {
    "name": "Information System Backup",
    "satisfiedBy": [
      {
        "default:SQLInstance:sqluser-dep": "spec.settings.backupConfiguration.enabled: true"
      }
    ]
  },
  "PE-18": {
    "name": "Location Of Information System Components",
    "satisfiedBy": [
      {
        "default:SQLInstance:sqluser-dep": "spec.region: northamerica-northeast1"
      }
    ]
  },
  "SC-8": {
    "name": "Transmission Confidentiality And Integrity",
    "satisfiedBy": [
      {
        "default:SQLInstance:sqluser-dep": "spec.settings.ipConfiguration.requireSsl: true"
      }
    ]
  }
}
```

???
We turned some of the ITSG-33 security controls into data we can use for this proof of concept, just to 
show what is possible when your data matches your deployed system.  Imagine being able to run a script 
on demand and have the full set of security controls you cover returned to you.

---
class: nord-dark, left, middle

### The ingredients for an automated ATO?

* Kubernetes: 56 data types
* Config Connector: 91 data types
* 147 Lego blocks, that can build any system (Tracker uses 26)
* Each has ~2-10 properties relevant to answering our questions:
  * Does it meet policy requirements?
  * Is it configured securely?
  * Does it follow best practice?

???
As someone going through the ATO/SA&A process right now, this slide is a dream scenario to me -- an automated, 
continuous ATO process.  We have everything we need to make it happen.

---

class: nord-dark, left, middle

### We (Security) need experiments like this

* Dev: ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©ğŸ©<br/>
* Ops: ğŸ¦†ğŸ¦†ğŸ¦†ğŸ¦†ğŸ¦†ğŸ¦†ğŸ¦†ğŸ¦†ğŸ¦†ğŸ¦†
* Sec: ğŸˆ

???
Doing things this way also allows for easier integration of the SA&A/ATO process throughout development.  If
your developers know which controls they need to satisfy and have a tool that can verify them, it makes
the right thing to do the easy thing to do.

---

class: nord-dark, left, middle

### Making security visible empowers everyone to work on this problem

* Dev: ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ<br/>
* Ops: ğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆğŸˆ
* Sec: ğŸˆ

???
So we want to selfishly make everyone on into a security cat.

---

class: nord-dark, left, middle

## Other Fun Uses of "as data"
### What other problems can data solve?

---

class: nord-dark, left, middle

### Domains: A single authoritative source for GoC Domains

```json
"CSE-CST": {
  "acronym_en": "CSE",
  "acronym_fr": "CST",
  "organization_en": "Communications Security Establishment",
  "organization_fr": "Centre de la s\u00e9curit\u00e9 des t\u00e9l\u00e9communications",
  "domains": [
      "ccirc-ccric.ca",
      "cse-cst-gc.ca",
      "ccirc-ccric.gc.ca",
      "cse-cst.gc.ca",
      "cyber.gc.ca",
      "getcybersafe.gc.ca",
      "pensezcybersecurite.gc.ca",
      "geekweek.ca",
      "getcybersafe.ca",
      "pensezcybersecurite.ca",
      "getcybersafe.com",
      "pensezcybersecurite.com"
  ]
},

```

???
So, do we have any other ways to leverage data in our system?  One of the things I found quite difficult throughout the Tracker 
development process was trying to find an authoritative list of GC domains.  There were a few lists floating around, but they were
wildly different.  We spent some time curating domains and ended up creating a repo that we now ingest on a nightly basis before we
perform our scans.  This gives GC departments a single place to update their domains that need to be measured and helps ensure we 
have the most up to date domains to scan.

---

class: nord-dark, left, middle

### ITSP.40.062 Guidance on Securely Configuring Network Protocols

```json 
{
  "ciphers": {
    "1.2": {
      "recommended": [
        "TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384",
        "TLS_ECDHE_ECDSA_WITH_AES_256_CCM",
        "TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256",
        "TLS_ECDHE_ECDSA_WITH_AES_128_CCM",
        "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384",
        "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"
      ], 
 ...
```

???
Another place we're leveraging data is with the guidance we're providing.  We've turned the TLS portion of ITSP.40.062 into a JSON repo
that we also ingest every night before our scans.  Before doing this, our guidance was manually entered into our database based on our
interpretation of a document.  This helps streamline the guidance we're using and also allows this data to be ingested for use in 
other systems.

---

class: nord-dark, middle, center

## Questions?

    </textarea>

    <script src="js/remark.min.js"></script>
    <script>
      var slideshow = remark.create({
        ratio: "16:9",
        highlightStyle: "dark",
        highlightLines: true,
        countIncrementalSlides: false,
        navigation: {
          scroll: false,
          touch: true,
          click: false
        }
      });

    </script>
  </body>
</html>
